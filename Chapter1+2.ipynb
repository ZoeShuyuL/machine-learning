{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4953fb21-d4fc-446f-a9a2-9930e6bc3d89",
   "metadata": {},
   "source": [
    "## Types of machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd5973-78f8-4c8a-98c9-540768bb72d4",
   "metadata": {},
   "source": [
    "supervised learning; unsupervised learning; reinforcement learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad32131-fc16-42a4-aae3-cfd202bd16ff",
   "metadata": {},
   "source": [
    "## An object-oriented perceptron API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9262e9-ed5b-4dac-8ec2-dd96aeeb5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    b_ : Scalar\n",
    "      Bias unit after fitting.\n",
    "    errors_ : list\n",
    "      Number of misclassifications (updates) in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float_(0.)\n",
    "        \n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fcf91-f9bc-48a6-aad0-1fbedb80422f",
   "metadata": {},
   "source": [
    "#### Example: iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6258967b-9359-47bc-b475-27966b2d8925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    s = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    print('From URL:', s)\n",
    "    df = pd.read_csv(s,\n",
    "                     header=None,\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "except HTTPError:\n",
    "    s = 'iris.data'\n",
    "    print('From local Iris path:', s)\n",
    "    df = pd.read_csv(s,\n",
    "                     header=None,\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8bdfdb-3cd4-4ccd-b9ba-12297c1a0da5",
   "metadata": {},
   "source": [
    "#### Training perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ebf18d2-4518-4b20-b311-bc466e69b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# select setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100, [0, 2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c173d-016f-46d6-90a2-29e864ae05c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:50, 0], X[:50, 1],\n",
    "            color='red', marker='o', label='Setosa')\n",
    "plt.scatter(X[50:100, 0], X[50:100, 1],\n",
    "            color='blue', marker='s', label='Versicolor')\n",
    "\n",
    "plt.xlabel('Sepal length [cm]')\n",
    "plt.ylabel('Petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# plt.savefig('images/02_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f7fdf-a45f-42f0-9e88-2c24c849fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model \n",
    "ppn = Perceptron(eta=0.1, n_iter=10)\n",
    "\n",
    "ppn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd888b9-4029-495a-ac66-59b5bb7803e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot \n",
    "plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of updates')\n",
    "\n",
    "# plt.savefig('images/02_07.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830aac63-03c3-44e8-b3e9-12d728178a1e",
   "metadata": {},
   "source": [
    "#### Adaptive linear neurons and the convergence of learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e94ad-ca02-4be3-a009-03b73e5db015",
   "metadata": {},
   "source": [
    "Minimizing cost functions with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37bf3c65-7470-478e-a6ea-d8f80c6ebe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement \n",
    "class AdalineGD:\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    b_ : Scalar\n",
    "      Bias unit after fitting.\n",
    "    losses_ : list\n",
    "      Mean squared eror loss function values in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.losses_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            # Please note that the \"activation\" method has no effect\n",
    "            # in the code since it is simply an identity function. We\n",
    "            # could write `output = self.net_input(X)` directly instead.\n",
    "            # The purpose of the activation is more conceptual, i.e.,  \n",
    "            # in the case of logistic regression (as we will see later), \n",
    "            # we could change it to\n",
    "            # a sigmoid function to implement a logistic regression classifier.\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            \n",
    "            #for w_j in range(self.w_.shape[0]):\n",
    "            #    self.w_[w_j] += self.eta * (2.0 * (X[:, w_j]*errors)).mean()\n",
    "            \n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * 2.0 * errors.mean()\n",
    "            loss = (errors**2).mean()\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d8529-233e-493b-b1d5-27a4d1e63561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot \n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "ada1 = AdalineGD(n_iter=15, eta=0.1).fit(X, y)\n",
    "ax[0].plot(range(1, len(ada1.losses_) + 1), np.log10(ada1.losses_), marker='o')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('log(Mean squared error)')\n",
    "ax[0].set_title('Adaline - Learning rate 0.1')\n",
    "\n",
    "ada2 = AdalineGD(n_iter=15, eta=0.0001).fit(X, y)\n",
    "ax[1].plot(range(1, len(ada2.losses_) + 1), ada2.losses_, marker='o')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Mean squared error')\n",
    "ax[1].set_title('Adaline - Learning rate 0.0001')\n",
    "\n",
    "# plt.savefig('images/02_11.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231bc36-ef36-4838-ac58-b831e6ecad54",
   "metadata": {},
   "source": [
    "#### Improving gradient descent through feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ce18a-45ab-48b7-a953-b43f91fb121e",
   "metadata": {},
   "source": [
    "standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da3a1b87-eb24-46e7-bee9-6ad46722afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "X_std = np.copy(X)\n",
    "X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()\n",
    "X_std[:, 1] = (X[:, 1] - X[:, 1].mean()) / X[:, 1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69171a71-91b5-48dc-b4c9-951899ff54a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_gd = AdalineGD(n_iter=20, eta=0.5)\n",
    "ada_gd.fit(X_std, y)\n",
    "\n",
    "plot_decision_regions(X_std, y, classifier=ada_gd)\n",
    "plt.title('Adaline - Gradient descent')\n",
    "plt.xlabel('Sepal length [standardized]')\n",
    "plt.ylabel('Petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/02_14_1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(ada_gd.losses_) + 1), ada_gd.losses_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean squared error')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/02_14_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a00f7b-281b-4e77-a749-ec7c0e3711f6",
   "metadata": {},
   "source": [
    "#### Large scale machine learning and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "087d22dd-ad10-4e16-97b8-89122750d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineSGD:\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    shuffle : bool (default: True)\n",
    "      Shuffles training data every epoch if True to prevent cycles.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    b_ : Scalar\n",
    "        Bias unit after fitting.\n",
    "    losses_ : list\n",
    "      Mean squared error loss function value averaged over all\n",
    "      training examples in each epoch.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.w_initialized = False\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self._initialize_weights(X.shape[1])\n",
    "        self.losses_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            if self.shuffle:\n",
    "                X, y = self._shuffle(X, y)\n",
    "            losses = []\n",
    "            for xi, target in zip(X, y):\n",
    "                losses.append(self._update_weights(xi, target))\n",
    "            avg_loss = np.mean(losses)\n",
    "            self.losses_.append(avg_loss)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
    "        if not self.w_initialized:\n",
    "            self._initialize_weights(X.shape[1])\n",
    "        if y.ravel().shape[0] > 1:\n",
    "            for xi, target in zip(X, y):\n",
    "                self._update_weights(xi, target)\n",
    "        else:\n",
    "            self._update_weights(X, y)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):\n",
    "        \"\"\"Shuffle training data\"\"\"\n",
    "        r = self.rgen.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "    \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"Initialize weights to small random numbers\"\"\"\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=m)\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.w_initialized = True\n",
    "        \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
    "        output = self.activation(self.net_input(xi))\n",
    "        error = (target - output)\n",
    "        self.w_ += self.eta * 2.0 * xi * (error)\n",
    "        self.b_ += self.eta * 2.0 * error\n",
    "        loss = error**2\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dec5e6-7ded-4239-b9f1-41d9d0ff81bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_sgd = AdalineSGD(n_iter=15, eta=0.01, random_state=1)\n",
    "ada_sgd.fit(X_std, y)\n",
    "\n",
    "plot_decision_regions(X_std, y, classifier=ada_sgd)\n",
    "plt.title('Adaline - Stochastic gradient descent')\n",
    "plt.xlabel('Sepal length [standardized]')\n",
    "plt.ylabel('Petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/02_15_1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(ada_sgd.losses_) + 1), ada_sgd.losses_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average loss')\n",
    "\n",
    "plt.savefig('figures/02_15_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541fd97-00f5-4c4a-82c6-2e646d7ff8ae",
   "metadata": {},
   "source": [
    "### Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ed6f9-894b-47b5-8193-224e12912cf7",
   "metadata": {},
   "source": [
    "plotting decision regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a560c-dda9-413a-96b1-396afaaa2a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=f'Class {cl}', \n",
    "                    edgecolor='black')\n",
    "plot_decision_regions(X, y, classifier=ppn)\n",
    "plt.xlabel('Sepal length [cm]')\n",
    "plt.ylabel('Petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "#plt.savefig('images/02_08.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
